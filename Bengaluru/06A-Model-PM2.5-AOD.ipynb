{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./config.ini']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"./config.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd19a2_obj = pickle.load(open(\"./mcd19a2.pkl\", \"rb\"))\n",
    "mcd19a2_longitude, mcd19a2_latitude = mcd19a2_obj['longitude'], mcd19a2_obj['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationName</th>\n",
       "      <th>StationId</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>BTM Layout, Bengaluru - CPCB</td>\n",
       "      <td>KA002</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.916576</td>\n",
       "      <td>77.610116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>BWSSB Kadabesanahalli, Bengaluru - CPCB</td>\n",
       "      <td>KA003</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.960388</td>\n",
       "      <td>77.718993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Bapuji Nagar, Bengaluru - KSPCB</td>\n",
       "      <td>KA004</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.956780</td>\n",
       "      <td>77.539729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>City Railway Station, Bengaluru - KSPCB</td>\n",
       "      <td>KA005</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.975840</td>\n",
       "      <td>77.565756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Hebbal, Bengaluru - KSPCB</td>\n",
       "      <td>KA006</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>13.035400</td>\n",
       "      <td>77.598800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Hombegowda Nagar, Bengaluru - KSPCB</td>\n",
       "      <td>KA007</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.937500</td>\n",
       "      <td>77.594900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Peenya, Bengaluru - CPCB</td>\n",
       "      <td>KA009</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>13.028513</td>\n",
       "      <td>77.519676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Sanegurava Halli, Bengaluru - KSPCB</td>\n",
       "      <td>KA010</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.915518</td>\n",
       "      <td>77.585666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Silk Board, Bengaluru - KSPCB</td>\n",
       "      <td>KA011</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.917710</td>\n",
       "      <td>77.623786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                StationName StationId       City   Latitude  \\\n",
       "77             BTM Layout, Bengaluru - CPCB     KA002  Bengaluru  12.916576   \n",
       "78  BWSSB Kadabesanahalli, Bengaluru - CPCB     KA003  Bengaluru  12.960388   \n",
       "79          Bapuji Nagar, Bengaluru - KSPCB     KA004  Bengaluru  12.956780   \n",
       "80  City Railway Station, Bengaluru - KSPCB     KA005  Bengaluru  12.975840   \n",
       "81                Hebbal, Bengaluru - KSPCB     KA006  Bengaluru  13.035400   \n",
       "82      Hombegowda Nagar, Bengaluru - KSPCB     KA007  Bengaluru  12.937500   \n",
       "83                 Peenya, Bengaluru - CPCB     KA009  Bengaluru  13.028513   \n",
       "84      Sanegurava Halli, Bengaluru - KSPCB     KA010  Bengaluru  12.915518   \n",
       "85            Silk Board, Bengaluru - KSPCB     KA011  Bengaluru  12.917710   \n",
       "\n",
       "    Longitude  \n",
       "77  77.610116  \n",
       "78  77.718993  \n",
       "79  77.539729  \n",
       "80  77.565756  \n",
       "81  77.598800  \n",
       "82  77.594900  \n",
       "83  77.519676  \n",
       "84  77.585666  \n",
       "85  77.623786  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df = pd.read_pickle('../2015-2020-pm25/india_stations.pkl')\n",
    "stations_df = stations_df[stations_df['City'] == 'Bengaluru']\n",
    "stations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ids = [file.split(\"/\")[-1][:5] for file in glob.glob(\"./dl_models/*.pkl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(46)\n",
    "train_stations = list(np.random.choice(station_ids, size=6, replace=False))\n",
    "test_stations  = list(set(station_ids) - set(train_stations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KA004', 'KA003', 'KA006', 'KA007', 'KA009', 'KA011']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KA002']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATIONS = {}\n",
    "\n",
    "def add_in_dict(row):\n",
    "    LOCATIONS[row[1]] = (row[0], row[2], row[3])\n",
    "\n",
    "[add_in_dict(row) for row in stations_df[['StationName', 'StationId', 'Latitude', 'Longitude']].values];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_point_idx(latitude, longitude, user_lat, user_lon):\n",
    "        \n",
    "    R = 6371000\n",
    "    lat1 = np.radians(user_lat)\n",
    "    lat2 = np.radians(latitude)\n",
    "    delta_lat = np.radians(latitude-user_lat)\n",
    "    delta_lon = np.radians(longitude-user_lon)\n",
    "    a = (np.sin(delta_lat/2))*(np.sin(delta_lat/2))+(np.cos(lat1))*(np.cos(lat2))*(np.sin(delta_lon/2))*(np.sin(delta_lon/2))\n",
    "    c = 2*np.arctan2(np.sqrt(a),np.sqrt(1-a))\n",
    "    d = R*c\n",
    "    \n",
    "    x, y = np.unravel_index(d.argmin(),d.shape)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_3x3_grid(data, x, y):\n",
    "    \n",
    "    if x < 1:\n",
    "        x += 1\n",
    "    if x > data.shape[0]-2:\n",
    "        x -= 2\n",
    "    if y < 1:\n",
    "        y += 1\n",
    "    if y > data.shape[1]-2:\n",
    "        y -= 2  \n",
    "    \n",
    "    three_by_three = data[x-1:x+2,y-1:y+2]\n",
    "    three_by_three = three_by_three.astype(float)\n",
    "    \n",
    "    not_nans = np.count_nonzero(~np.isnan(three_by_three))\n",
    "    \n",
    "    if not_nans == 0:\n",
    "        return {\n",
    "            \"x\": x,\n",
    "            \"y\": y,\n",
    "        }\n",
    "    else:\n",
    "        three_by_three_average = np.nanmean(three_by_three)\n",
    "        three_by_three_std = np.nanstd(three_by_three)\n",
    "        three_by_three_median = np.nanmedian(three_by_three)\n",
    "        \n",
    "        return {\n",
    "            \"x\": x,\n",
    "            \"y\": y,\n",
    "            \"data\": three_by_three,\n",
    "            \"average\": three_by_three_average,\n",
    "            \"std\": three_by_three_std,\n",
    "            \"median\": three_by_three_median\n",
    "        }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_lat_lon(station_lat, station_lon):\n",
    "    x, y = get_nearest_point_idx(mcd19a2_latitude, mcd19a2_longitude, station_lat, station_lon)\n",
    "    nearest_lon, nearest_lat = np.round(mcd19a2_longitude[x,y], 8), np.round(mcd19a2_latitude[x,y], 8)\n",
    "    \n",
    "    return x, y, nearest_lat, nearest_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def extract_date_from_file_name(FILE_NAME):\n",
    "    return datetime.datetime.strptime(FILE_NAME.split('/')[-1].split('.')[1:][0][1:], \"%Y%j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = config['convert']['hdf_path'] + \"*.hdf\"\n",
    "FILE_LIST = glob.glob(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhdf import SD\n",
    "import multiprocessing as mp\n",
    "\n",
    "manager = mp.Manager()\n",
    "rows = manager.list()\n",
    "\n",
    "\n",
    "def perform_task(idx):\n",
    "\n",
    "    # ------------- Data Loading Start ------------------\n",
    "\n",
    "    SDS_NAME = \"Optical_Depth_047\"\n",
    "    FILE_NAME = FILE_LIST[idx]\n",
    "    hdf = SD.SD(FILE_NAME)\n",
    "    sds = hdf.select(SDS_NAME)\n",
    "\n",
    "    NAME = FILE_NAME.split('/')[-1]\n",
    "\n",
    "    data = sds.get()\n",
    "\n",
    "    attributes = sds.attributes()\n",
    "    scale_factor = attributes['scale_factor']\n",
    "    fv = attributes['_FillValue']\n",
    "\n",
    "    data = data.astype(float)\n",
    "    data[data == fv] = np.nan\n",
    "    data = np.nanmean(data, axis=0)\n",
    "\n",
    "    scaled_data = data * scale_factor\n",
    "\n",
    "    # ------------- Data Loading End ------------------\n",
    "\n",
    "    date = extract_date_from_file_name(FILE_NAME)\n",
    "    \n",
    "    # ------------- AOD Extraction Start --------------\n",
    "\n",
    "    for sub_idx in range(len(station_ids)):\n",
    "\n",
    "        station_id = station_ids[sub_idx]\n",
    "        station_name, station_lat, station_lon = LOCATIONS[station_id]\n",
    "        x_coord, y_coord, nearest_lat, nearest_lon = nearest_lat_lon(station_lat, station_lon)\n",
    "\n",
    "        try:\n",
    "            fix_station_aod = get_nearest_3x3_grid(scaled_data, x_coord, y_coord)['average'].round(3)\n",
    "\n",
    "            row = [date.strftime(\"%Y-%m-%d\"), station_id, fix_station_aod, nearest_lat, nearest_lon]\n",
    "            rows.append(row)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # ------------- AOD Extraction End --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(mp.cpu_count())\n",
    "pool.map(perform_task, [idx for idx in range(len(FILE_LIST))])\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.array(list(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aod_df = pd.DataFrame(rows, columns=['date', 'station_id', 'aod', 'latitude', 'longitude'])\n",
    "aod_df['date'] = pd.to_datetime(aod_df['date'], format='%Y-%m-%d')\n",
    "aod_df = aod_df.set_index(['date', 'station_id'])\n",
    "aod_df = aod_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>aod</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>station_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2019-10-03</th>\n",
       "      <th>KA004</th>\n",
       "      <td>0.71</td>\n",
       "      <td>12.96080067</td>\n",
       "      <td>77.54263828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KA006</th>\n",
       "      <td>0.813</td>\n",
       "      <td>13.03586322</td>\n",
       "      <td>77.60128382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2019-10-25</th>\n",
       "      <th>KA006</th>\n",
       "      <td>0.426</td>\n",
       "      <td>13.03586322</td>\n",
       "      <td>77.60128382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KA009</th>\n",
       "      <td>0.423</td>\n",
       "      <td>13.02752294</td>\n",
       "      <td>77.51918007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-28</th>\n",
       "      <th>KA002</th>\n",
       "      <td>0.53</td>\n",
       "      <td>12.91909925</td>\n",
       "      <td>77.61301293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2019-12-29</th>\n",
       "      <th>KA004</th>\n",
       "      <td>0.993</td>\n",
       "      <td>12.96080067</td>\n",
       "      <td>77.54263828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KA007</th>\n",
       "      <td>1.027</td>\n",
       "      <td>12.93577982</td>\n",
       "      <td>77.58955471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KA009</th>\n",
       "      <td>1.021</td>\n",
       "      <td>13.02752294</td>\n",
       "      <td>77.51918007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2019-12-30</th>\n",
       "      <th>KA002</th>\n",
       "      <td>1.135</td>\n",
       "      <td>12.91909925</td>\n",
       "      <td>77.61301293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KA011</th>\n",
       "      <td>1.128</td>\n",
       "      <td>12.91909925</td>\n",
       "      <td>77.62474204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         aod     latitude    longitude\n",
       "date       station_id                                 \n",
       "2019-10-03 KA004        0.71  12.96080067  77.54263828\n",
       "           KA006       0.813  13.03586322  77.60128382\n",
       "2019-10-25 KA006       0.426  13.03586322  77.60128382\n",
       "           KA009       0.423  13.02752294  77.51918007\n",
       "2019-10-28 KA002        0.53  12.91909925  77.61301293\n",
       "...                      ...          ...          ...\n",
       "2019-12-29 KA004       0.993  12.96080067  77.54263828\n",
       "           KA007       1.027  12.93577982  77.58955471\n",
       "           KA009       1.021  13.02752294  77.51918007\n",
       "2019-12-30 KA002       1.135  12.91909925  77.61301293\n",
       "           KA011       1.128  12.91909925  77.62474204\n",
       "\n",
       "[184 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df_pm25_list = pd.read_pickle('../2015-2020-pm25/india_stations_pm25.pkl')\n",
    "pm25_values_df_list = []\n",
    "\n",
    "for df in stations_df_pm25_list:\n",
    "    if (df['StationId'].iloc[0] in station_ids):\n",
    "        pm25_values_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = config['convert']['start_date']\n",
    "END = config['convert']['end_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_window_impute(station_df, window_length=14):\n",
    "    column = \"PM2.5\"\n",
    "    try:\n",
    "        for idx, value in enumerate(station_df[column].values):\n",
    "            if np.isnan(value):\n",
    "                station_df[column][idx] = station_df[column][idx - window_length]\n",
    "    except:\n",
    "        pass\n",
    "    return station_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pm25_values_df_list)):\n",
    "    df = pm25_values_df_list[i]\n",
    "    nan_count = df.isna().sum()['PM2.5']\n",
    "    \n",
    "    if (nan_count):\n",
    "        df = previous_window_impute(df)\n",
    "        nan_count = df.isna().sum()['PM2.5']\n",
    "        if (nan_count):\n",
    "            print(df['StationId'].values[0])\n",
    "    \n",
    "    pm25_values_df_list[i] = pm25_values_df_list[i][START:END]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_df = pd.DataFrame(columns=pm25_values_df_list[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pm25_values_df_list)):\n",
    "    pm25_df = pm25_df.append(pm25_values_df_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_df = pm25_df.reset_index()\n",
    "pm25_df.columns = [\"date\", \"station_id\", \"PM2.5\"] \n",
    "pm25_df = pm25_df.set_index(['date', 'station_id'])\n",
    "pm25_df = pm25_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([aod_df, pm25_df], axis=1).dropna().astype(\"float64\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "random_state = 42\n",
    "\n",
    "ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = merged_df[~merged_df['station_id'].isin(test_stations)]\n",
    "test_df  = merged_df[merged_df['station_id'].isin(test_stations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = ['aod']\n",
    "y_columns = ['PM2.5']\n",
    "\n",
    "X_train, y_train = train_df[X_columns].values, train_df[y_columns].values.reshape(-1,1)\n",
    "X_test, y_test = test_df[X_columns].values, test_df[y_columns].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polynomial_reg_model():\n",
    "    \n",
    "    poly_reg = PolynomialFeatures()\n",
    "    X_poly = poly_reg.fit_transform(X_train)\n",
    "\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_poly, y_train)\n",
    "\n",
    "    y_pred = regressor.predict(poly_reg.transform(X_test))\n",
    "    score = {\n",
    "        \"r2_score\": r2_score(y_test, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred), \n",
    "        \"MSLE\": mean_squared_log_error(y_test, y_pred),\n",
    "        \"MdAbsE\": median_absolute_error(y_test, y_pred),\n",
    "        \"MAPE\": mean_absolute_percentage_error(y_test, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        \"mean\": np.mean(y_test)\n",
    "    }\n",
    "    \n",
    "    return regressor, score, poly_reg\n",
    "\n",
    "def get_linear_reg_model():\n",
    "    \n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    score = {\n",
    "        \"r2_score\": r2_score(y_test, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred), \n",
    "        \"MSLE\": mean_squared_log_error(y_test, y_pred),\n",
    "        \"MdAbsE\": median_absolute_error(y_test, y_pred),\n",
    "        \"MAPE\": mean_absolute_percentage_error(y_test, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        \"mean\": np.mean(y_test)\n",
    "    }\n",
    "    \n",
    "    return regressor, score, None\n",
    "\n",
    "def get_decision_tree_reg_model():\n",
    "    \n",
    "    regressor = DecisionTreeRegressor(random_state=random_state)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = regressor.predict(X_test)\n",
    "    score = {\n",
    "        \"r2_score\": r2_score(y_test, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred), \n",
    "        \"MSLE\": mean_squared_log_error(y_test, y_pred),\n",
    "        \"MdAbsE\": median_absolute_error(y_test, y_pred),\n",
    "        \"MAPE\": mean_absolute_percentage_error(y_test, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        \"mean\": np.mean(y_test)\n",
    "    }\n",
    "    \n",
    "    return regressor, score, None\n",
    "\n",
    "def get_random_forest_reg_model():\n",
    "    \n",
    "    regressor = RandomForestRegressor(random_state=random_state)\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    score = {\n",
    "        \"r2_score\": r2_score(y_test, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred), \n",
    "        \"MSLE\": mean_squared_log_error(y_test, y_pred),\n",
    "        \"MdAbsE\": median_absolute_error(y_test, y_pred),\n",
    "        \"MAPE\": mean_absolute_percentage_error(y_test, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        \"mean\": np.mean(y_test)\n",
    "    }\n",
    "    \n",
    "    return regressor, score, None\n",
    "\n",
    "def get_svr_reg_model():\n",
    "    \n",
    "    sc_X = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    X_train_sc = sc_X.fit_transform(X_train)\n",
    "    y_train_sc = sc_y.fit_transform(y_train)\n",
    "    \n",
    "    regressor = SVR(kernel='rbf')\n",
    "    regressor.fit(X_train_sc, y_train_sc)\n",
    "    \n",
    "    y_pred = sc_y.inverse_transform(regressor.predict(sc_X.transform(X_test)))\n",
    "    score = {\n",
    "        \"r2_score\": r2_score(y_test, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred), \n",
    "        \"MSLE\": mean_squared_log_error(y_test, y_pred),\n",
    "        \"MdAbsE\": median_absolute_error(y_test, y_pred),\n",
    "        \"MAPE\": mean_absolute_percentage_error(y_test, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        \"mean\": np.mean(y_test)\n",
    "    }\n",
    "    \n",
    "    return regressor, score, (sc_X, sc_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST = [\n",
    "    ('Polynomial', get_polynomial_reg_model),\n",
    "    ('Linear', get_linear_reg_model),\n",
    "    ('Decision Tree', get_decision_tree_reg_model),\n",
    "    ('Random Forest', get_random_forest_reg_model),\n",
    "    ('SVR', get_svr_reg_model),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSLE</th>\n",
       "      <th>MdAbsE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>14.226610</td>\n",
       "      <td>20.020470</td>\n",
       "      <td>0.259888</td>\n",
       "      <td>10.728918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>14.228820</td>\n",
       "      <td>19.397858</td>\n",
       "      <td>0.258909</td>\n",
       "      <td>12.114153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Regression</td>\n",
       "      <td>17.380402</td>\n",
       "      <td>21.284743</td>\n",
       "      <td>0.367165</td>\n",
       "      <td>15.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Regression</td>\n",
       "      <td>16.191672</td>\n",
       "      <td>20.538998</td>\n",
       "      <td>0.318362</td>\n",
       "      <td>14.378300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVR Regression</td>\n",
       "      <td>13.735576</td>\n",
       "      <td>20.209101</td>\n",
       "      <td>0.248096</td>\n",
       "      <td>9.318453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model        MAE       RMSE      MSLE     MdAbsE\n",
       "0     Polynomial Regression  14.226610  20.020470  0.259888  10.728918\n",
       "1         Linear Regression  14.228820  19.397858  0.258909  12.114153\n",
       "2  Decision Tree Regression  17.380402  21.284743  0.367165  15.740000\n",
       "3  Random Forest Regression  16.191672  20.538998  0.318362  14.378300\n",
       "4            SVR Regression  13.735576  20.209101  0.248096   9.318453"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = {}\n",
    "best_score = 9e9\n",
    "\n",
    "rows = []\n",
    "\n",
    "for name, model_fn in MODEL_LIST:\n",
    "    regressor, score, scaler = model_fn()\n",
    "    row = [f\"{name} Regression\", score['MAE'], score['RMSE'], score['MSLE'], score['MdAbsE']]\n",
    "    rows.append(row)\n",
    "    \n",
    "    if score['RMSE'] < best_score:\n",
    "        best['name'] = name + \" Regression\"\n",
    "        best['regressor'] = regressor\n",
    "        best['scaler'] = scaler\n",
    "        best['score'] = score\n",
    "        \n",
    "        best_score = score['RMSE']\n",
    "\n",
    "model_dfs = pd.DataFrame(rows, columns=[\"model\", \"MAE\", \"RMSE\", \"MSLE\", \"MdAbsE\"])\n",
    "model_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "{} &                     model &     MAE &    RMSE &   MSLE &  MdAbsE \\\\\n",
      "\\midrule\n",
      "0 &     Polynomial Regression &  14.227 &  20.020 &  0.260 &  10.729 \\\\\n",
      "1 &         Linear Regression &  14.229 &  19.398 &  0.259 &  12.114 \\\\\n",
      "2 &  Decision Tree Regression &  17.380 &  21.285 &  0.367 &  15.740 \\\\\n",
      "3 &  Random Forest Regression &  16.192 &  20.539 &  0.318 &  14.378 \\\\\n",
      "4 &            SVR Regression &  13.736 &  20.209 &  0.248 &   9.318 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_dfs.round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(config['convert'][\"aod_pm25\"], \"wb\") as file:\n",
    "    pickle.dump(best, file, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_columns = ['aod']\n",
    "X_columns = ['PM2.5']\n",
    "\n",
    "X_train, y_train = train_df[X_columns].values, train_df[y_columns].values.reshape(-1,1)\n",
    "X_test, y_test = test_df[X_columns].values, test_df[y_columns].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSLE</th>\n",
       "      <th>MdAbsE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.151215</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>0.072327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.100525</td>\n",
       "      <td>0.147894</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>0.074721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Regression</td>\n",
       "      <td>0.132345</td>\n",
       "      <td>0.178440</td>\n",
       "      <td>0.012106</td>\n",
       "      <td>0.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Regression</td>\n",
       "      <td>0.117805</td>\n",
       "      <td>0.163011</td>\n",
       "      <td>0.009981</td>\n",
       "      <td>0.091260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVR Regression</td>\n",
       "      <td>0.088498</td>\n",
       "      <td>0.142416</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.053624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model       MAE      RMSE      MSLE    MdAbsE\n",
       "0     Polynomial Regression  0.101746  0.151215  0.008278  0.072327\n",
       "1         Linear Regression  0.100525  0.147894  0.007978  0.074721\n",
       "2  Decision Tree Regression  0.132345  0.178440  0.012106  0.088000\n",
       "3  Random Forest Regression  0.117805  0.163011  0.009981  0.091260\n",
       "4            SVR Regression  0.088498  0.142416  0.007156  0.053624"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = {}\n",
    "best_score = 9e9\n",
    "\n",
    "rows = []\n",
    "\n",
    "for name, model_fn in MODEL_LIST:\n",
    "    regressor, score, scaler = model_fn()\n",
    "    row = [f\"{name} Regression\", score['MAE'], score['RMSE'], score['MSLE'], score['MdAbsE']]\n",
    "    rows.append(row)\n",
    "    \n",
    "    if score['RMSE'] < best_score:\n",
    "        best['name'] = name + \" Regression\"\n",
    "        best['regressor'] = regressor\n",
    "        best['scaler'] = scaler\n",
    "        best['score'] = score\n",
    "        \n",
    "        best_score = score['RMSE']\n",
    "\n",
    "model_dfs = pd.DataFrame(rows, columns=[\"model\", \"MAE\", \"RMSE\", \"MSLE\", \"MdAbsE\"])\n",
    "model_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "{} &                     model &    MAE &   RMSE &   MSLE &  MdAbsE \\\\\n",
      "\\midrule\n",
      "0 &     Polynomial Regression &  0.102 &  0.151 &  0.008 &   0.072 \\\\\n",
      "1 &         Linear Regression &  0.101 &  0.148 &  0.008 &   0.075 \\\\\n",
      "2 &  Decision Tree Regression &  0.132 &  0.178 &  0.012 &   0.088 \\\\\n",
      "3 &  Random Forest Regression &  0.118 &  0.163 &  0.010 &   0.091 \\\\\n",
      "4 &            SVR Regression &  0.088 &  0.142 &  0.007 &   0.054 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_dfs.round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(config['convert'][\"pm25_aod\"], \"wb\") as file:\n",
    "    pickle.dump(best, file, protocol=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
